Kinesis --> Analytics Service

Kinesis Essentials --> 
    Video Streams --> stream video to AWS, real-time or batch video processing and analytics
    Data Streams -->  
        --> ingest data from many sources
        --> real-time data processing application
        --> Kinesis connector -- EMR
        --> Data processed in sequence
        --> Server Side Encryption
      major components -->
        --> stream --> contains one or more shards
        --> shards --> (processing power) --> 1 MB/sec data input (write) and 2MB/sec data output (read)
                             --> distribute data to shards using partition key
        --> producer --> data creator
        --> consumer --> data consumer
    Firehose --> load streaming data to S3, Redshift, ElastCache, Splunk
    Data Analytics --> Run SQL queries against Data Streams or Firehose
    
Kinesis Benefits -->
    Real-time processing --> continously collect data and, build applications that analyze the data as it gets generated
    Parallel processing --> multiple kinesis consumer applications can be processing the same incoming data streaming concurrently.
    Durable --> Kinesis Synchronously replicates the streaming data across three data centers within a single AWS region and preserves the data for upto 7 days (24 hours by default)
    Scalable --> can stream from as little as few MB to several TB per hour

When to Use / Where to use -->
    Gaming --> collect data like players actions, feed the data into gaming platform 
            (a reactive plateform based off of players real-time actions)
    Real-time Analytics --> Collect IOT (sensors) data from many sources at high amount of frequency and process it using kinesis
    Application alerts --> monitors application logs in real-time and trigger events based on data
    Log / event data collection --> log data from any number of devices, real-time data anlytics dashboard, stores in S3
    mobile data capture --> all mobile devices can push data simultaneously to kinesis as it produced

Kinesis Producers --> IOT devices (sensors), cell phone devices
     --> producers are devices that produce and sends data to Kinesis
     --> you can setup producers to continously input data into Kinesis Stream
     --> you can easily scale (up or down) producers as per need
     --> more producer means more shard you need
     --> Kinesis APIs --> PutRecord, PutRecords
     --> Kinesis Producer Library --> java library that sends data to stream
     --> Kinesis Agent --> stream files from linux server

Kinesis Consumers --> multiple consumers can consume Kinesis stream's data concurrently
      --> Kinesis Consumers Library --> Java Library (EC2) --> wrapper for other languages
                        --> launches a consumer for each shard
                        --> auto scaling
      --> Lambda can read stream data
      --> Kinesis connector for EMR

Kinesis with Lambda --> https://aws.amazon.com/blogs/big-data/preprocessing-data-in-amazon-kinesis-analytics-with-aws-lambda/
    Many customers use Amazon Kinesis to ingest, analyze, and persist their streaming data.  One of the easiest ways to gain real-time insights into your streaming data is to use Kinesis Analytics.  It enables you to query the data in your stream or build entire streaming applications using SQL.  Customers use Kinesis Analytics for things like filtering, aggregation, and anomaly detection.

Kinesis Analytics now gives you the option to preprocess your data with AWS Lambda.  This gives you a great deal of flexibility in defining what data gets analyzed by your Kinesis Analytics application. You can also define how that data is structured before it is queried by your SQL.

    ------------ from aCloudGuru -------
    Streaming Data --> It is continously generated data in/by applications in small size (i.e, in KBs), through thousands of data resources 
      at same time.
  Kinesis --> AWS service for easily load and analyze streaming data.
  3 category of Kinesis service -->
    1. Kinesis stream
    2. K Firehose
    3. K Analytics
  1. Kinesis Stream -->
      All incoming data are stored in multiple Shard for default 24 hours (and can be increased to 7 days) --> Data retention period
      Shards --> high read/write throughput with distributed environment
      Kinesis Stream can not guarantee order of data across multiple shards, its possible only within shards.
  2. Kinesis Firehose --> Its more automated way of Kinesis Streams.
      >> In this we don't need to manage shards 
      >> data in automaticaly stored to S3 after processing. Consumer services can access from S3 anytime
      >> you can't directly send data to RedShift or RDS or DynamoDB, it has to go to S3 first then to any other services.
      >> Firehose can send data directly to S3, ESC (ElasticSearch Cluster)
     For security concerns -->
        --> enable server-side data encryption, But you can only do this if you use a Kinesis data stream as your data source. Firehose no longer stores the data at rest.
        --> When you send data from your data producers to your Kinesis data stream, Kinesis Data Streams encrypts your data using an AWS KMS key before storing it at rest. 
     
  3. Kinesis Analytics -->
      >> Allows user to write SQLs and analyze data that exists in FireHose or Stream.
