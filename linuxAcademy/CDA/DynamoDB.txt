??????  and DynamoDB Accelerator (DAX)?????

DynamoDB Overview --> 
    1. Fully managed NoSQL DB --> 
          AWS auto scale compute resources for you based on setup
          customer need to manage data, not to worry about DB software/hardware
          provides built-in monitoring system
          schema-less, stores data in the form of key-value pair
          high availability, scalable, elastic, fault tolerant
    2. consistent and fast performance --> 
          fast SSD used in hardware, 
          control throughput using RCU/WCU, 
          replication on multi-AZ, 
          Global table allow replication across multi-region
    3. easy to setup and communicate with --> using AWS console/API/CLI/SDK, DynamoDB Stream advanced feature to use across AWS services
    4. optional encryption at rest
    5. Popular use-cases, example:- IOT (storing meta-data), Gaming info, mobile user session info, etc
    6. Easily integrates with other AWS services like, EMR, Lambda

DynamoDB Pricing --> below are main components to calculate pricing
  provisioned throughput Writes (WCU - write capacity unit) --> monthly rate per WCU
  Provisioned throughput Reads (RCU - Read capacity unit) --> monthly rate per RCU
  Indexed data storage -- (secondary index) --> hourly rate per GB of table data
  Other pricing factors --> (pricing differ based on region and over-time) and pricing are prorated based on hours
    Reserved capacity --> reserve WCU/RCU for fixed low price
    auto scaling, --> free, just pay for WCU/RCU
    global tables, --> (rWCU) in-case of global table replication, additional replication WCU
    on-demand backup, --> pay per GB month stored
    on-demand restore, --> pay per GB restored
    DynamoDB Accellerator (DAX), --> pay for the instances used per hour
    DynamoDB Streams --> pay per 100K reads

DynamoDB core concepts -->
    DynamoDB supports optimistic locking using java SDK --> this stretagy ensures that client-side item that you are updating or deleting is the same item as in DynamoDB table. DB writes are protected by being overwritten.

DynamoDB Partitions --> DynamoDB stores data in partitions, partitions are SSD allocation of storage for tables, replicated across AZs.
       --> number of partition determines by provisioned capacity and storage size of partition
partition Key --> (required), also known as HASH attribute of item, scalar in nature (means holds only one value), 
sort key --> (not-required), also known as Range attribute, scalar in nature (holds only one value), used to sort data within partition
primary key --> uniquely identify each item to avoid duplicate rows, must be of type string, number, or binary
    2 types --> 
      simple primary key {only partition key} --> each item must have unique value for this attribute
      composite primary key {partition key + sort key} --> two item can have same partition key or sort key, but combination should be unique and such item are required to have both key.

AWS documentation, ideal way to construct partition key -->
    1. use high-cardinality attribute (refers to the uniqueness of data values contained in a particular column (attribute) of a database table.)

Items --> (1 byte to 400 kb) group of attributes that can be uniquely indetifiable, (similar as row of RDBMS)
Attributes --> fundamental data element of dynamodb (same as individual column of RDBMS)
    data types supported --> 
      scalar type --> String, number, binary, boolean, null
      document type --> List, Map
      set --> number sets, string sets, binary sets
Item Collection (size limit) --> The max size of item collection is 10 GB, means for any distinct partition key value, the sum of item size in table plus the sum of item sizes across all of that tables LSI must not exceed 10 GB.
        --> This limit does not apply to table without LSI.

DynamoDb provision throughput --> measured in Read and Write Capacity unit
  its maximum amount of capacity that application can consume, after that request are throttled (canceled or stoped)
  throttled can be avoided by using DynamoDB auto scaling feature
  throughput sets at table level, but split-up and consumed at partition level. Means, one partition can lack capacity but others are fine. Hence, complete table will not suffer with performance only one partition with slight difference
Exam tips --> 
    seconds vs minutes vs hours - WCU and RCU are number of writes and reads per second. always round-up and calculate throughput per sec
    rounding --> round-up to nearest 1 KB (for WCU) and nearest 4 KB (for RCU)

Provisioned Capacity units --> 
1. Write Capacity Unit --> WCU consumed when creating, deleting, updating items. Writes always follow strong consistency.
   1 WCU = 1 write of item of size 1 KB (or less) per second
   example:- how many WCU needed for a table to have 120 writes per min for each item of size 2.5 KB
   Answer:- WCU = 120 item/min * 2.5 KB = 120 item/60 sec * 3 KB (nearest 1 KB) = 6 WCU
 
2. Read Capacity Unit --> RCU consumed when GetItem and BatchGetItem operation performed. Using the QUERY or SCAN opration
  RCU supports both strong consistency and Eventual Consistency -->
In-case of Strong Consistency --> 
   1 RCU = 1 read of 1 item of size 4 KB (or less) per second
   example:- how many RCU needed for a table to read 10 items each of 13KB to read per sec
   Answer:- RCU = 10 items * (13KB/ 4KB per RCU) = 10 items * (3.25KB per RCU) = 10 items * (4KB rounded to nearest 4KB per RCU) = 40 RCU
In-case of Eventually Consistency --> half of RCU will be needed compared to Strong Consistency

DynamoDB Read Operations -->
  GetItem --> read single item based on given primary key
  BatchGetItem --> can read upto 100 items from one or more table (each item read is done by GetItem operation, and RCU calculated)
  QUERY --> read item(s) with the same partition key value, (sort key if provided), 
      --> all returned items are treated as single read operation, and sum the size of all items and rounded to 4KB for RCU calculation
  SCAN --> read all the item(s) and consider the size of items evaluated by operation, not the size of returned item. means, returned item could be less than the evaluated items.
       --> all returned items are treated as single read operation, and sum the size of all items and rounded to 4KB for RCU calculation
       --> SCAN operation should be avoided by using queries or secondary indexes. 
       --> Avoid SCAN on mission critical tables as they can take up large amount of read capacity
       --> Try to perform parallel scan operation instead of sequential scan. This can improve performance.
****** there is limit of 1MB of data returned from these operations, to get more data need to provide LastEvaluatedKey  
***** QUERY and SCAN operation both support eventual consistent read by default, but can configure to request consistent reads.
**** QUERY operation vs GETITEM operation -->
    GETITEM --> returns attributes based on provided primary key only (means based on partition key only)
    QUERY --> returns attributes based on provided primary key only (can use both partition key as well as sort key)
Advantages of QUERY over SCAN --->
    ---> Returns the item matching the primary key search, return all attributes of item or only the one you request.
    --> much more efficient because it searches indexes only
  
Atomic Counters --> DynamoDB writes applied in the order received, if operation fails they can be retried. This brings a risk of updating item twice, possibly under or overcounting.
Hence, conditional writes are introduced. means each write operation will be performed based on some conditional check.
 
**** very imp for exam *** 
DynamoDB Secondary Indexes --> allows efficient queries on non-primary key attributes
  every secondory index is associated with only one table, but one table can have multiple Secondary index
  This is an awesome feature of DynamoDB, DynamoDB automatically maintains the secondary index. Means, when base table gets updates, DynamoDB updates secondary index as well.
**** AWS doesn't allow increase in limit of secondary indexes. by default each table in an account can have 5 LSI and 5 GSI.
  
  Local Secondary Index --> gives the choice of Sort Keys
    Each LSI can act as another sort key. 
    LSI primary-key are composite key {partition key + sort key}
    LSI consumes WCU and RCU from main tables capacity
    LSI must be created at the same time table is created. Can't create later.
  Global Secondary Index --->
    allows different partition and different sort key from the main table partition key and sort key
    means you can query the table in differnt ways
    Strongly consistent reads not possible with GSI
    GSI has their own WCU and RCU
    GSI can be created even after table creation, using either CLI, SDK or through console

Common DynamoDB errors and limits --> 
  throttlingException --> when you try to create, delete or update tables too quickly
  ProvisionedThroughputExceedException --> if throughput on the table is insufficient to support read and write operation
  ResourceNotFoundException --> requested table does not exist or is too early in CREATING state

go through more errors here:- https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/CommonErrors.html

DynamoDB Limits -->
  1. secondary indexes --> total 10 (5 LSI and 5 GSI)
  2. provisioned throughput default limits --> these limit includes sum of table and GSI both
            --> minimum is 1RCU and 1WCU for any table or GSI
            --> maximum is -->
                --> for US East (N. Virginia) Region --> Per table – 40,000 RCU/WCU  or Per account – 80,000 RCU/WCU
                --> All other Region --> Per table – 10,000 RCU/WCU  or Per account – 20,000 RCU/WCU
  3. number of tables
  4. items and attributes
  5. specific API limits
    
 go through more limits here:- https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html
 
Popular Use cases -->
    IOT --> Storing meta-data
    Gaming --> storing session information, LeaderBoard
    Mobile --> Storing User profiles, personalization

DynamoDB APIs --> https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.API.html
UpdateItem --> 
CreateTable – Creates a new table. Optionally, you can create one or more secondary indexes, and enable DynamoDB Streams for the table.
DescribeTable– Returns information about a table, such as its primary key schema, throughput settings, index information, and so on.
ListTables – Returns the names of all of your tables in a list.
UpdateTable – Modifies the settings of a table or its indexes, creates or remove new indexes on a table, or modifies DynamoDB Streams settings for a table.
DeleteTable – Removes a table and all of its dependent objects from DynamoDB.

 DynamoDB Stream --> 
 https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html 
 https://aws.amazon.com/blogs/database/dynamodb-streams-use-cases-and-design-patterns/
 
   --> DynamoDB Streams captures a time-ordered sequence of item-level modifications in any DynamoDB table, and stores this information in a log for up to 24 hours. Applications can access this log and view the data items as they appeared before and after they were modified, in near real time.
    --> A DynamoDB stream is an ordered flow of information about changes to items in an Amazon DynamoDB table. you need to enable a stream on a table.
        --> by default stream captures primary key attribute(s) of the items that were modified
        --> You can configure the stream so that the stream records capture additional information, such as the "before" and "after" images of modified items.

DynamoDB Streams guarantees the following -->
    --> Each stream record appears exactly once in the stream.
    --> For each item that is modified in a DynamoDB table, the stream records appear in the same sequence as the actual modifications to the item.
    --> DynamoDB Streams writes stream records in near real time, so that you can build applications that consume these streams and take action based on the contents.      
  
****** AWS maintains separate endpoints (URL/ARN) for DynamoDB and DynamoDB Streams.
naming convention -->
    streams.dynamodb.<region>.amazonaws.com
   dynamoDB table endpoint --> dynamodb.us-west-2.amazonaws.com  
   dynamoDB stream endpoint --> streams.dynamodb.us-west-2.amazonaws.com

Every stream is uniquely identified by an Amazon Resource Name (ARN). Here is an example ARN for a stream on a DynamoDB table named TestTable:
    arn:aws:dynamodb:us-west-2:111122223333:table/TestTable/stream/2015-05-11T21:21:33.291

DynamoDB management console --> select table --> Manage Stream window --> enable any of below options
    Keys only—only the key attributes of the modified item.
    New image—the entire item, as it appears after it was modified.
    Old image—the entire item, as it appeared before it was modified.
    New and old images—both the new and the old images of the item.

Using CLI -->
use the CreateTable or UpdateTable APIs to enable or modify a stream. The StreamSpecification parameter determines how the stream is configured:
    StreamEnabled — specifies whether a stream is enabled (true) or disabled (false) for the table.
    StreamViewType — specifies the information that will be written to the stream whenever data in the table is modified:
        KEYS_ONLY—only the key attributes of the modified item.
        NEW_IMAGE—the entire item, as it appears after it was modified.
        OLD_IMAGE—the entire item, as it appeared before it was modified.
        NEW_AND_OLD_IMAGES—both the new and the old images of the item.

DynamoDB Encryption at Rest --> 
    --> using an AWS Key Management Service (AWS KMS) managed encryption key 
    --> you need to create a table with encryption at rest enabled. (Encryption at rest can be enabled only when you are creating a new DynamoDB table. can't enable encryption at rest on an existing table. once enabled, it can't be disabled. )
    --> Copy data from existing table to new encrypted table
