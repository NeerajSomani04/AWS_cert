S3 (simple storage service) --> object storage
You can store virtually any kind of data in any format.
objects size 0 bytes to 5 TB
simple key-based object storage service
REST web services interface
Pay-as-you-go pricing and unlimited capacity 
objects are automatically stored across multiple AZ (3) within specified region
Region is a geographic location, which contains one or more AZ (which is isolated location, which are connected with low latency, high throughput, and highly redundant networking.)



S3 Storage Classes --> 4 types:
    1. S3 Standard --> high durability, availability, and performance. S3 Lifecycle management offers configurable policies to 
              automatically migrate objects to the most appropriate storage class.
    2. S3 Standard-Infrequent Access --> accessed less frequently, but requires rapid access when needed.
          high durability, high throughput, and low latency of S3 Standard, with a low per GB storage price and per GB retrieval fee. 
          Lifecycle management offers
          performance is same as S3 Standard
          You can directly PUT into S3 Standard-IA by specifying STANDARD_IA in the x-amz-storage-class header.
          Billing --> charges for an S3 Standard-IA COPY request and an S3 Standard-IA data retrieval.
          **vimp (could come in exam) --> The S3 Standard-IA storage class is set at the object level and can exist in the same bucket as the S3 Standard or S3 One Zone-IA storage classes, allowing you to use S3 Lifecycle policies to automatically transition objects between storage classes without any application changes.
          minimum storage duration charge for S3 Standard-IA -->  full 30 days
          minimum object storage charge for S3 Standard-IA --> 128KB in size (For example, a 6KB object in S3 Standard-IA will incur S3 Standard-IA storage charges for 6KB and an additional minimum object size fee equivalent to 122KB at the S3 Standard-IA storage price.)
          99% availability
    3. S3 One Zone-Infrequent Access --> stores data in a single AZ. accessed less frequently, but requires rapid access when needed.
              costs 20% less than Standard-Infrequent Access
              **vimp (could come in exam) --> The S3 Standard-IA storage class is set at the object level and can exist in the same bucket as the S3 Standard or S3 One Zone-IA storage classes, allowing you to use S3 Lifecycle policies to automatically transition objects between storage classes without any application changes.
              99% availability
    4. Amazon Glacier --> secure, durable, and extremely low-cost storage service for data archiving. ($0.004 per gigabyte per month)
              provides three options for access to archives, from a few minutes to several hours.
              you can't use Amazon Glacier APIs to access objects, that archived to Amazon Glacier. Objects are only accessible through, Amazon S3 APIs or the Amazon S3 Management Console.
              The retrieval request creates a temporary copy of your data in the S3 RRS or S3 Standard-IA storage class while leaving the archived data intact in Amazon Glacier.
              Amazon Glacier storage is priced based on monthly storage capacity and the number of  Lifecycle transition requests into Amazon Glacier.
              minimum 90 days of storage charge for any object.
              You can retrieve 10GB of your Amazon Glacier data per month for free with the AWS free tier.
              If you delete 1GB of data 30 days after uploading it, you will be charged an early deletion fee for 60 days of Amazon Glacier storage.
         3 retrival options:-- 
                Expedited, --> For all but the largest objects (250MB+), within  1-5 min
                Standard --> between 3-5 hours
                Bulk --> within 5-12 hours 
              
S3 Billing --> Pay-as-you-go
      Billing prices are based on the location of your bucket.
      no Data Transfer charge within Region
      COPY request between AWS Regions is charged at standard rates
      Billing calculation based on following -->
          a. storage used
          b. Network Data Transferred In:
          c. Network Data Transferred Out:
          d. Data Requests: (Get/ PUT/ Delete requests)
          e. Data Retrieval: only applies to --> S3 Standard-IA and S3 One Zone-IA storage classes
      
      Normal Amazon S3 rates apply for every version of an object stored or requested.
      There is option to configure your bucket as a Requester Pays bucket, in which case the requester will pay the cost of requests and downloads of your Amazon S3 data.
      
 Security --> S3 is secure by default. 
      --> User can do SSE (server side encryption)
      --> user can enable encryption option -- S3 buckets to automatically encrypt objects before storing them. (SSL encryption)
    
    control access to S3 --> 4 ways:
            Identity and Access Management (IAM) policies, --> users, groups, roles access
            bucket policies, --> customers can define rules which apply broadly across all requests
            Access Control Lists (ACLs), --> customers can grant specific permissions (i.e. READ, WRITE, FULL_CONTROL) to specific users for an individual bucket or object
            and Query String Authentication. --> customers can create a URL to an Amazon S3 object which is only valid for a limited time.
 
     auditing controls --> 
          configure S3 bucket to create access log records for all requests
          
     S3 Data Encryption at Rest --> 4 ways
          SSE-S3 --> Amazon handles key management and key protection
          SSE-C --> if you want to maintain your own encryption keys, but don’t want to implement or leverage a client-side encryption library.
          SSE-KMS --> usage master key on top of encryption key providing an additional layer of control. AWS KMS provides an audit trail logs.
          encryption client library --> you retain control of the keys and complete the encryption and decryption of objects client-side
      
     VPC Endpoint for Amazon S3 is a logical entity within a VPC that allows connectivity only to S3.
     S3 bucket policies now support a condition, aws:sourceVpce, that you can use to restrict access.
     
     Amazon Macie is an AI-powered security service that helps you prevent data loss by automatically discovering, classifying, and protecting sensitive data stored in Amazon S3. 

S3 Durability & Data Protection -->     
        99.999999999% durability (11 --> 9's)
        Best practice for Data Protection --> best practice includes secure access permissions, Cross-Region Replication, versioning, and a functioning, regularly tested backup. 
        Versioning allows --> on any PUT, POST, COPY, or DELETE operation. This is helpful for accidental recovery.
        You can use Lifecycle rules along with Versioning to implement a rollback window
        Versioning’s Multi-Factor Authentication (MFA) Delete capability can be used to provide an additional layer of security. 
        
Q:  What checksums does Amazon S3 employ to detect data corruption?
Answer --> combination of Content-MD5 checksums and cyclic redundancy checks (CRCs) to detect data corruption. 
        --> performs these checksums on data at rest and repairs
        
        
S3 "Query in Place" functionality -->
        Amazon S3 allows customers to run sophisticated queries against data stored without the need to move data into a separate analytics platform.
        multiple query options:
        S3 Select --> SQL expressions, like SELECT and WHERE, from delimited text files and JSON objects in Amazon S3. 
            use S3 Select with AWS Lambda to build serverless applications that use S3 Select to efficiently and easily retrieve data from Amazon S3 instead of retrieving and processing entire object.
        
        Amazon Athena --> easy to analyze data in Amazon S3 using standard SQL queries. 
            Athena is serverless
            works with a variety of standard data formats, including CSV, JSON, ORC, Apache Parquet and Avro. 
        
        Amazon Redshift Spectrum --> 
                enables you to run queries against exabytes of unstructured data in Amazon S3 with no loading or ETL required.
                Redshift Spectrum lets you separate storage and compute, allowing you to scale each independently.
                
S3 Event Notifications -->
            actions in Amazon S3 like PUTs, POSTs, COPYs, or DELETEs. Notification messages can be sent through either Amazon SNS, Amazon SQS, or directly to AWS Lambda.
            event notifications enable you to run workflows, send alerts, or perform other actions in response to changes in your objects stored in S3.
         
S3 Transfer Acceleration -->
     enables fast, easy, and secure transfers of files over long distances, leverages Amazon CloudFront’s globally distributed AWS Edge Locations.
     point your Amazon S3 PUT and GET requests to the s3-accelerate endpoint domain name. 
     two types of endpoints: .s3-accelerate.amazonaws.com or .s3-accelerate.dualstack.amazonaws.com
     At back end, AWS monitor for any specific task, if S3 Transfer Acceleration is not faster than Standard S3, then AWS will not charge client and may bypass S3 Transfer Acceleration.
     
     Q: choose between S3 Transfer Acceleration and Amazon CloudFront’s PUT/POST??
     Answer: for less than 1GB transfer prefer Amazon CloudFront’s PUT/POST
     
     Q: choose between S3 Transfer Acceleration and AWS Snow Family (Snowball, Snowball Edge, and Snowmobile)?
     Answer:- AWS Snow Family is ideal for customers moving large batches of data at once.
     
    Q: Can S3 Transfer Acceleration complement AWS Direct Connect?
    Answer: AWS Direct Connect is a good choice for customers who have a private networking requirement or who have access to AWS Direct Connect exchanges.
                S3 Transfer Acceleration is best for submitting data from distributed client locations over the public Internet, or where variable network conditions make throughput poor. Some AWS Direct Connect customers use S3 Transfer Acceleration to help with remote office transfers, where they may suffer from poor Internet performance.
    
    Q: Can S3 Transfer Acceleration complement the AWS Storage Gateway or a 3rd party gateway? -- same answer as below
    Q: Can S3 Transfer Acceleration complement 3rd party integrated software? -- same answer as below
    Answer: yes, client will see some benefit.
    
S3 Storage Management --> Using object tagging.
        --> Object tags can be replicated across AWS Regions using Cross-Region Replication. 
        --> Object tags are priced based on the quantity of tags and a request cost for adding tags.
   --> Storage Class Analysis, you can analyze storage access patterns and transition the right data to the right storage class. 
   --> its a daily update and there is price associated with it
   --> S3 Inventory report provides a scheduled alternative to Amazon S3’s synchronous List API. There is some price associated with it
   
   --> You can use CloudWatch to set thresholds on any of the storage metrics counts, timers, or rates and trigger an action when the threshold is breached. 
   
   --> CloudWatch storage metrics are provided for free. Cloudwatch custom request metrics are price

S3 Lifecycle management    --> 
    --> provides the ability to define the lifecycle of your object storage policy
    --> you can move objects from one storage class to another or remove completely from any storage.
    --> 
    
    Q:    Why would I use an S3 Lifecycle policy to expire incomplete multipart uploads?
        Answer: - The S3 Lifecycle policy that expires incomplete multipart uploads allows you to save on costs by limiting the time non-completed multipart uploads are stored. For example, if your application uploads several multipart object parts, but never commits them, you will still be charged for that storage. This policy can lower your S3 storage bill by automatically removing incomplete multipart&nbsp;uploads and the associated storage after a predefined number of days.

--> Amazon S3 supports all features of Cross-Region Replication (CRR).


         
         
