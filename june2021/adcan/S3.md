# Simple Storage Service (S3)
- It provides a near infinitely scalable object storage platform - accessible from anywhere with a public internet connection.
- read all S3 basics from this link (https://github.com/acantril/aws-sa-associate-saac02/blob/master/04-AWS-Fundamentals/00_LearningAids/S3Basics.pdf)
- **S3 is PRIVATE by default**
- by default only the person who created the bucket originally has access to it, permission to all other identity needs to be provided seperately.


### S3 Security (Resource Policies & ACLs)
- S3 Security is controlled via a combination of Identity Policies, Bucket Policies (Resource Policies) and Legacy Bucket and Object ACLs
- Bucket Policy Examples : https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html
- S3 bucket policy is a type of resource policy.
- A resource policy is just like an identity policy, but as the name suggest they are attached to resources instead of identities.
- The difference between resource policy and identity policy is all about perspective.
- Resource policy provides resource perspective permissions.
- With identity policy you are controlling what that identity can access, with resource policy you are controlling who can access that resource.
- Resource policy allow or deny permission to resources in same account or different accounts
- Resource policies can also allow or deny anonymous principals. 
  - Here principles means, AWS services like lambda, Ec2, etc, but not limited to AWS. Any other external application can also get permission, example, gmail account, dropbox, etc.
  - resource policies can be used to open a bucket to the world by referencing all principles even those not authenticated by AWS.
- Resource policy has one major difference to identity policy, that is presence of explicit "principal" component in the policy statement.
- There can be only one bucket policy per bucket, but it can have multiple statements.

### Identity Polices
- you can only attach identity policies to identities in your own account
- Hence, identity policy can only control security inside your own account.


## ACL (Access Control List)
- Its a way to apply security to objects and buckets
- They are sub-resource of that object or of that bucket
- Legacy, means its old, AWS don't recommend using it and prefer to use bucket policies instead.
- The reason it got removed, because its very inflexible and can perform very simple permission configurations. for example, they can't have conditions like bucket polcies.
- In general, there are only 5 permissions can be applied using ACL. which itself is very limited.
- ACL can be applied only on single object or single bucket. You can't apply it to group of objects or group of buckets.

### Block Public Access Settings
- This can be applied to only anonymous principles, meaning the identity or services that are not authenticated by your AWS account.
- The first out of four option, is to block public access that could be caused by any new ACL implemented.
- second option, to block public access granted by any ACL either new or old
- third option, allows any existing public access granted by bucket policies or access point policies. 
- fourth option, blocks both any existing and new bucket policies, from granting any public access.

### Exam powerup 
- Identity : Controlling different resources (bucket)
- Identity : You have a preference for IAM
- Identity : Same account
- Bucket : Just controlling S3
- Bucket : Anonymous or cross account
- ACLs : Never - Unless you must

### S3 Static Website Hosting
- Accessing S3 is generally done via APIs
- Static Website Hosting is a feature of the product which lets you define a HTTP endpoint, set index and error documents and use S3 like a website.
- S3 Pricing : https://aws.amazon.com/s3/pricing/
- Website endpoint is created
- custom domain via R53 - Bucketname matters

# S3 pricing
- based on storage
- based on data transfer, transfer data into S3 is free, but transfer data out of S3 is charged
- based on request operations (get, post, put, delete)
- based on management and analytics (s3 data analytics features)

### S3 Object versioning & MFA Delete
- Object versioning is a feature which can be enabled on an S3 bucket - allowing the bucket to store multi versions of objects
- These objects can be referenced by their version ID to interact directly - or omit this to reference the latest version of an object
- Objects aren't deleted - object deletion markers are put in place to hide objects.
- By default versioning is disabled, and user can enable it as per need. But once enabled, it can't be disabled.
- Although, versioning can be suspended and can be re-enabled again.
- When versioning of object is disabled, ID of the object is "NULL". But when versioning is enabled, every action (update/delete) creates new ID (random unique value) for that object to maintain versioning.
- If you want to retrieve a specific version of the object then just pass ID information as well in you request. If you don't specify ID means, you want the latest version of the object.
- In case of delete operation, S3 just put a delete marker on that specific object. This will hide the object from accessing it. but in reality this object is not deleted from bucket. you can remove this delete marker from object to retrieve this object back be accessible.
- Its possible to delete an object permanently, by specifying its ID with delete action.
- **MFADelete** 
  - its enabled in versioning configuration
  - means, MFA is required to change bucket versioning state
  - MFA is required to delete versions

### S3 performance optimization
- how S3 Uploads (PutObject) works ?
  - by default, any object is uploaded as single blob of data stream to S3
  - the problem with this is, if a stream fails, whole upload fails, and need to restart the full upload
  - Data Transfer protocols like, BitTorrent developed to allow speedy distributed transfer of data.
  - also, the limit of single put upload is 5 GB, but that itself is highly un-reliable
- Single PUT Upload
  - most of above points
- Multipart Upload
  - this is solution to above issue
  - This can be confugured, so that a large data can be divided into multiple small parts
  - min data size is 100 MB, meaning multi part can only be used if your original (full) file size is equal or more than 100 MB.
  - an upload can be divided into maximum of 10,000 parts. example, range between 5MB to 5GB
  - last part can be smaller than 5 MB
  - parts can fail, and be restarted
  - Transfer rate = speeds of all parts (highly improved)
- S3 Transfer Acceleration
  - it uses the convenience network of Edge location, end-user will upload data to edge location, and then it will be transferred to destination using AWS own reliable and fast network.
  - An S3 bucket needs to be enabled for transfer acceleration, by default its disabled.
    - The enabling of transfer acceleration comes with some restrictions and rules
      - bucket name can not contain periods
      - it needs to be DNS compatible in its naming
  - AWS Accelerated Transfer Tool : http://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html

### Key Management Service (KMS)
- its a regional and public service (but of-course you need permissions to access it)
- It allows user to create, store and manage keys
- these keys are used to convert plaintext to ciphertext and vice versa
- KMS is capable of handling both Symmetric and Asymmetric keys
- it can also be used for all cryptographic operations like encrypt, decrypt, etc
- **Exam imp point** -- Keys never leave KMS, it can only be used securely - provides FIPS 140-2 (L2)(security standard)
- Its also capable of managing CMK (Customer Master Key)
  - Its a logical item that contains few other items - ID, date, policy, description, state
  - every CMK is backed by physical key material
  - This key material can be generated by KMS or can be imported in KMS to encrypt or decrypt data
  - **exam imp** CMKs can be used to encrypt ot decrypt data for up to 4KB of size.
  - How to overcome this limitation
  - Use Data Encryption Keys
- Data Encryption Keys (DEKs)
  - This is also managed in KMS
  - This key can be generated inside KMS using CMK
  - This DEK can be utilized on larger data set (more than 4 KB)
  - DEK is always linked with some CMK
  - **most imp** KMS does not store the DEK in any way, KMS only provides it to user or service who requested it and then discards it.
  - The reason KMS doesn't keep it because it actually doesn't perform the encryption or decryption using DEK
  - It will be done by user or service who requested DEK

### Summary of KMS key concepts 
- CMKs are isolated to a region & never leave
- AWS managed CMKs or Customer Managed CMKS
- CMKs are more configurable, example edit key policy time to time
- Other AWS services can use the same CMK to perform operations.
- CMKs support key rotation
- rotation, is a process, in which actual physical key material is changed time to time.
- **exam imp** with AWS managed keys, rotation is always enabled (it can't be disabled) and it happend in every 3 years.
- **exam imp** with customer managed keys, rotation can be optional, but if enabled, it happens once a year.
- CMK itself contains current backing key (as well as any previous backing keys) 
- Alias can also be created to a particular CMK
- Key policies is also a type of resource policy
- Every CMKs has one key policy
- In every key policy you need to explicitely specify which AWS account that key trust. This is usually mentioned under principle component of key policy doc.
- with the combination of key policies and IAM policies, we can easily fine tune permissions of specific user.
- example, someone can encrypt the data using CMK but can't decrypt it. etc

### example of CMK commands
'''
# Shared
echo "find all the doggos, distract them with the yumz" > battleplans.txt

aws kms encrypt \
    --key-id alias/catrobot \
    --plaintext fileb://battleplans.txt \
    --output text \
    --query CiphertextBlob \
    --profile iamadmin-general | base64 \
    --decode > not_battleplans.enc 
    
aws kms decrypt \
    --ciphertext-blob fileb://not_battleplans.enc \
    --output text \
    --profile iamadmin-general \
    --query Plaintext | base64 --decode > decryptedplans.txt
'''
